{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from importlib import reload\n",
    "from pprint import pprint\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_level = 1\n",
    "msc_neuro_root = os.getcwd()\n",
    "    \n",
    "for i in range(subfolder_level): \n",
    "    msc_neuro_root = os.path.dirname(msc_neuro_root)\n",
    "        \n",
    "os.chdir(msc_neuro_root) # set msc_neuro's root as working directory\n",
    "if msc_neuro_root not in sys.path: # put it to path for package discovery\n",
    "    sys.path.append(msc_neuro_root)\n",
    "__inited = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NDN3.NDNutils as NDNutils\n",
    "import NDN3.NDN as NDN\n",
    "\n",
    "import utils.data as udata\n",
    "import utils.network as unet\n",
    "import utils.analysis as uas\n",
    "import utils.analysis_present as uasp\n",
    "import utils.analysis_graph as uasg\n",
    "import utils.misc as umisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(uasg)\n",
    "def analyse_and_summarize(*args, **kwargs):\n",
    "    uasg.summarize_experiments(*args, **kwargs)\n",
    "    return uasg.analyse_experiments(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_folder = \"./figures/\"\n",
    "os.makedirs(figs_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = uasg.analyse_experiments(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b1.*test\"), \n",
    "        (\"./training_data/logs/baseline\", \"b1.*__(1?[0-9]|2[0-4])[^0-9].*test\"),       \n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 35000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 1 (50 runs)\", \"baseline 1 (25 runs)\"],\n",
    "    title=\"Number of runs versus stability of quantile metric\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"04_runs_number.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = uasg.analyse_experiments(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b1.*__(1?[0-9]|2[0-4])[^0-9].*test\"),       \n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, float(\"inf\")),\n",
    "    static_data = [(\"HSM Antolik et al. (100 runs)\", (0.5011869918699188, 0.44278048780487816, 0.4789430894308944, _ , 35000))],\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 1 (25 runs)\"],\n",
    "    title=\"Baseline 1 performance\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_1_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b1.*__([0-9])[^0-9].*test\"),       \n",
    "        (\"./training_data/logs/experiments_1\", \"exp21.*test\"), \n",
    "        (\"./training_data/logs/experiments_1\", \"exp22.*test\")\n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5_000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 1 (10 runs)\"] + [\"input: mean 0, std 1 (10 runs)\", \"input: mean 0, std 1, output: std 1 (10 runs)\"],\n",
    "    title=\"Experiment 1.2.1: Input/output scale\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_2_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b1.*__(1?[0-9]|2[0-4])[^0-9].*test\"),       \n",
    "        (\"./training_data/logs/baseline\", \"b2.*test\"),       \n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300,float(\"inf\")),\n",
    "    static_data = [(\"HSM Antolik et al. (100 runs)\", (0.5011869918699188, 0.44278048780487816, 0.4789430894308944, _ , 35000))],\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 1 (25 runs)\"] + [\"baseline 2 (25 runs)\"],\n",
    "    title=\"Baseline 1 vs Baseline 2\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "fig.savefig(figs_folder + \"05_1_2_1_2.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b1.*__(1?[0-9]|2[0-4])[^0-9].*test\"),       \n",
    "        (\"./training_data/logs/baseline\", \"b2.*test\"),       \n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300,float(\"inf\")),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 1 (25 runs)\"] + [\"baseline 2 (25 runs)\"],\n",
    "    title=\"Baseline 1 vs Baseline 2\",\n",
    "    figsize=(4, 4)\n",
    ")\n",
    "fig.savefig(figs_folder + \"03_b1_vs_b3_mini.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b2.*__[0-9][^0-9].*test\"),       \n",
    "        (\"./training_data/logs/experiments_1\", \"exp41.*test\"),\n",
    "        (\"./training_data/logs/experiments_1\", \"exp51.*test\"),\n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5_000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 2: zero initialized biases, Poisson noise (10 runs)\"] + [\"truncated normal initialized biases (10 runs)\"] + [\"Gaussian noise (10 runs)\"],\n",
    "    title=\"Experiments 1.2.2: Gaussian noise, 1.2.3: Bias initialization\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_2_2.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b2.*__[0-9][^0-9].*test\"),       \n",
    "        (\"./training_data/logs/experiments_2\", \"bs2_exp1x0.*test\"),\n",
    "        (\"./training_data/logs/experiments_2\", \"bs2_exp1x2.*test\"),\n",
    "        (\"./training_data/logs/experiments_2\", \"bs2_exp1x3.*test\"),\n",
    "        (\"./training_data/logs/experiments_2\", \"bs2_exp1x4.*test\"),\n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5_000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 2: lr 0.0001 (10 runs)\"] + \n",
    "    [\n",
    "        \"lr 0.00001 (10 runs)\",\n",
    "        \"lr 0.0005 (10 runs)\",\n",
    "        \"lr 0.001 (10 runs)\",\n",
    "        \"lr 0.005 (10 runs)\",\n",
    "    ],\n",
    "    title=\"Experiment 1.2.4: Learning rates\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_2_4.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b2.*test\"),      \n",
    "        (\"./training_data/logs/baseline\", \"bl3.*test\"),       \n",
    "\n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300,float(\"inf\")),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 2 (25 runs)\", \"baseline 3 (25 runs)\"],\n",
    "    title=\"Baseline 2 vs Baseline 3\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "fig.savefig(figs_folder + \"05_1_2_5.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"bl3.*__[0-9][^0-9].*test\"),       \n",
    "    ] + [ (\"./training_data/logs/experiments_2\", f\"bs3_exp2x{i}[^0-9].*test\") for i in range(0, 9, 2) if i != 2], \n",
    "    'loss/correlation/correlation',\n",
    "    (1000, float(\"inf\")),\n",
    "    normalize_steps=True,\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 3: batch size 16, epochs 5 000 (10 runs)\"] + [f\"batch size {x}, epochs {y} (10 runs)\" for (x, y) in [(2, 5000), (64, 20000), (512, 160000),(1800, 562500), ]],\n",
    "    title=\"Experiment 1.2.6: Batch size\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_2_6.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [ (\"./training_data/logs/baseline\", \"bl3.*__[0-9][^0-9].*test\") ] +       \n",
    "    [ (\"./training_data/logs/experiments_2\", f\"bs3_exp11_2x{i}[^0-9].*test\") for i in [1, 7, 13, 5, 11, 17]] + \n",
    "    [ ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 3: dropout 0, hidden size 20 % (10 runs)\"] + [f\"dropout {x}, hidden size {y} % (10 runs)\" for (x, y) in [\n",
    "        (0.05, 20), (0.05, 30), (0.05, 40), (0.5, 20), (0.5, 30), (0.5, 40)\n",
    "    ]],\n",
    "    title=\"Experiment 1.3.1: Dropout\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_3_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [ (\"./training_data/logs/baseline\", \"bl3.*__[0-9][^0-9].*test\") ]       \n",
    "    + [ (\"./training_data/logs/experiments_2\", f\"bs3_exp52x{i}[^0-9].*test\") for i in [3, 7]]\n",
    "    + [ (\"./training_data/logs/experiments_2\", f\"bs3_exp5x{i}[^0-9].*test\") for i in [15, 5, 0]], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 3: no-reg, hidden size 20 % (10 runs)\"] + [f\"both reg {x}, hidden size {y} % (10 runs)\" for (x, y) in [\n",
    "        (\"L2 1\", 20), (\"L2 1\", 40), (\"L2 0.1\", 40), (\"L2 0.1\", 20), (\"L1 0.1\", 20),\n",
    "    ]],\n",
    "    title=\"Experiment 1.3.2: L1/L2 on both hidden\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_3_2.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize( \n",
    "    [ (\"./training_data/logs/baseline\", \"bl3.*__[0-9][^0-9].*test\") ] +       \n",
    "    [ (\"./training_data/logs/experiments_2\", f\"bl3_exp12x{i}[^0-9].*test\") for i in [2, 6, 22]] + \n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (300, float(\"inf\")),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 3: no-reg, size 20 % (10 runs)\"] + [f\"reg: {x}, hidden size {y} % (10 runs)\" for (x, y) in [\n",
    "        (\"hidden L2 0, output 0.1\", 20), (\"hidden L2 0.05, output 0.1\", 20), (\"hidden L2 0.05, output 0.1\", 30),\n",
    "    ]],\n",
    "    title=\"Experiment 1.3.3: L1 on hidden and/or output\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_3_3.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/baseline\", \"b1.*__(1?[0-9]|2[0-4])[^0-9].*test\"),       \n",
    "        (\"./training_data/logs/baseline\", \"b2.*test\"),\n",
    "        (\"./training_data/logs/baseline\", \"bl3.*test\"),\n",
    "        (\"./training_data/logs/baseline\", \"bl4.*test\"),\n",
    "    ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, float(\"inf\")),\n",
    "    static_data = [(\"HSM Antolik et al. (100 runs)\", (0.5011869918699188, 0.44278048780487816, 0.4789430894308944, _ , 35000))],\n",
    "    median_mode=True,\n",
    "    override_legend=[f\"baseline {x} (25 runs)\" for x in range(1, 5, 1)],\n",
    "    title=\"Baseline models comparisons\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "fig.savefig(figs_folder + \"05_1_5_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "     (\"./training_data/logs/baseline\", \"bl3.*__[0-9][^0-9].*test\")       \n",
    "    ] + [ (\"./training_data/logs/experiments_2\", f\"bs3_exp10x{i}[^0-9].*test\") for i in range(6) if i not in [3]], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    override_legend=[f\"baseline 3: no-linscale, normalized (10 runs)\"] + [f\"{x}, {y} (10 runs)\" for (x, y) in \n",
    "        [(\"linscale\", \"normalized\"), (\"linscale\", \"0-255\"), (\"linscale\", \"0-0.000255\"), (\"no-linscale\", \"0-255\"), (\"no-linscale\", \"0-0.000255\")]],\n",
    "    title=\"Experiment 1.4.1: Input scaling\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_1_4_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp1x{i}[^0-9].*test\") for i in [12, 18, 10]] +\n",
    "    [(\"./training_data/logs/baseline\", \"b2.*__[0-9][^0-9].*test\"),]  \n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5001),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [f\"LNLN hidden: {x}, size {y} %, last: L2 0.1 (10 runs)\" for (x, y) in [\n",
    "        (\"laplacian 0.1\", 20), (\"laplacian 10\", 20), (\"laplacian 0\", 20),\n",
    "    ]] + [\"baseline 2 (10 runs)\"],\n",
    "    title=\"Experiment 2.1.1: LNLN\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_2_1_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp2x{i}[^0-9].*test\") for i in [0, 5, 11]] +\n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5001),\n",
    "    static_data = [(\"rLN Antolik et al. (1 run)\", (0.31, 0.31, 0.31, _ , 5000))],\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [f\"LN laplacian {x} (10 runs)\" for (x, y) in [\n",
    "        (\"0\", 20), (\"1\", 20), (\"100 000\", 20),\n",
    "    ]] + [\"baseline 2 (25 runs)\"],\n",
    "    title=\"Experiment 2.1.2: LN\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_2_1_2.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp5x{i}[^0-9].*test\") for i in [174, 180, 210, 216, 228]] +\n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (10, 5001),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [f\"convolution: {x}, laplacian {y}, hidden: max 1 (10 runs)\" for (x, y) in \n",
    "            [(\"9 filters, 3 pixels\", 0.01), (\"9 filters, 3 pixels\", 0.1),(\"30 filters, 7 pixels\", 0.01), (\"30 filters, 7 pixels\", 0.1),(\"9 filters, 15 pixels\", 0.1) ]],\n",
    "    title=\"Experiment 2.2.1: convolutions instead of DoG\",\n",
    "    figsize=[8, 5],\n",
    "    ylim=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_2_2_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp5x{i}[^0-9].*test\") for i in [180, 61, 13, 64,]] +\n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (10, 5001),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [\"convolution 9 filters, 3 pixels laplacian 0.1, hidden fully connected max 1 (10 runs)\"] + \n",
    "            [f\"convolution: {x}, laplacian {y}, hidden separable: {z} 0.1 (10 runs)\" for (x, y, z) in \n",
    "            [(\"30 filters, 15 pixels\", 0.01, \"L1\"),(\"30 filters, 3 pixels\", 0.01, \"L1\"), (\"30 filters, 15 pixels\", 0.01, \"L2\"), ]],\n",
    "    title=\"Experiment 2.2.2: convolutions instead of DoG and the separable layer\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_2_2_2.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_4\", f\"bs4_exp9x{i}[^0-9].*test\") for i in [152, 15, 3, 202]] +\n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [f\"conv DoG: filters {x}, pixels {y}, {z}: L1 {w}\" for (x, y, z, w) in \n",
    "                                               [(30, 15, \"fully-connected\", 0.1), (30, 15, \"separable\", 0.01), (30, 3, \"separable\", 0.01), (4, 15, \"separable\", 0.01)]],\n",
    "    title=\"Experiment 2.2.3: Convolutional Difference of Gaussian \",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_2_2_3.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_4\", f\"bs4_exp9x{i}[^0-9].*test\") for i in [152, 15]] +\n",
    "    [ (\"./training_data/logs/experiments_4\", f\"bs4_exp10x{i}[^0-9].*test\") for i in [305, 202]] +\n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5001),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [f\"conv DoG: filters {x}, pixels {y}, {z}: L1 {w}\" for (x, y, z, w, q) in \n",
    "                        [(30, 15, \"fully-connected\", 0.1, \"nonlinearity\"),(30, 15, \"separable\", 0.01, \"nonlinearity\"),\n",
    "                         (9, 7, \"fully-connected\", 0.1, \"linear\"),(9, 15, \"separable\", 0.01, \"linear\"),                                                                        ]],\n",
    "    title=\"Experiment 2.2.4: Convolutional DoG without non-linearity\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"05_2_2_4.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analyse_and_summarize(\n",
    "    [\n",
    "        (\"./training_data/logs/experiments_3\", \"bs4[^_].*__[0-9][^0-9].*test\"),\n",
    "    ]\n",
    "    +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp8x{i}[^0-9].*test\") for i in [125,]] +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp5x{i}[^0-9].*test\") for i in [61,]] +\n",
    "    [ (\"./training_data/logs/experiments_3\", f\"bs4_exp1x{i}[^0-9].*test\") for i in [12,]] +\n",
    "    []\n",
    "    , \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 6000),\n",
    "    static_data = [(\"what/where by Klindt et al. (1 run)\", (0.55, 0.55, 0.55, _ , 5000))],\n",
    "    median_mode=True,\n",
    "    override_legend=[\"baseline 4 (10 runs)\"] + [\"what/where-like: best variant (10 runs)\", \"convolution, separable (10 runs)\", \"LNLN (10 runs)\"],\n",
    "    title=\"Experiment 2.2.5: What/where reimplementation \",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "\n",
    "fig.savefig(figs_folder + \"./figs/05_2_2_5.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg in range(1, 4):\n",
    "    sd = [\n",
    "            [(\"HSM Antolik et al. (100 runs)\", (0.5011869918699188, 0.44278048780487816, 0.4789430894308944, _ , 35000))],\n",
    "            [(\"HSM Antolik et al. (100 runs)\", (0.43486727161769717, 0.3824422930076944, 0.41198434773542036  , _ , 35000))],\n",
    "            [(\"HSM Antolik et al. (100 runs)\", (0.4487798926942876, 0.41864551024628077, 0.4377441857934202, _ , 35000))],\n",
    "        ][reg-1]\n",
    "    fig = analyse_and_summarize(\n",
    "        [(\"./training_data/logs/experiments_multeval\", f\"multieval_bl4_{i}.*test\") for i in [reg]] +\n",
    "        [(\"./training_data/logs/experiments_multeval\", f\"multieval_bl2_{i}.*test\") for i in [reg]] +\n",
    "        [(\"./training_data/logs/experiments_multeval\", f\"multieval_exp5_{i}.*test\") for i in [reg]] +\n",
    "        [(\"./training_data/logs/experiments_multeval\", f\"multieval_exp1_{i}.*test\") for i in [reg]] +\n",
    "        [(\"./training_data/logs/experiments_multeval\", f\"multieval_exp10_{i}.*test\") for i in [reg]] +\n",
    "\n",
    "        []\n",
    "        , \n",
    "        'loss/correlation/correlation',\n",
    "        (300, float(\"inf\")),\n",
    "        static_data = sd,\n",
    "        median_mode=True,\n",
    "        override_legend=[\"baseline 4 (10 runs)\", \"baseline 2 (10 runs)\", \"convolution, separable (10 runs)\", \"LNLN (10 runs)\", \"convolutional DoG, fully connected, linear (10 runs)\"],\n",
    "        title=f\"Various architectures on region {reg}\",\n",
    "        figsize=[8, 5.5]\n",
    "    )\n",
    "    fig.savefig(figs_folder + f\"05_3_2_1_{reg}.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_analysis(experiments, combine_coef_sets, tag, limit_steps=None, experiments_log_in_legend=True, override_legend=None, title=None, enable_legend = True, figsize=(20, 10), **kwargs):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    line_handles = []\n",
    "    legend_names = []\n",
    "    \n",
    "    for combine_set in combine_coef_sets:\n",
    "        \n",
    "        (combine_coefs, combine_label) = combine_set if type(combine_set) is tuple else (combine_set, \"Combined\")\n",
    "        \n",
    "        if len(combine_coefs) < 1:\n",
    "            continue\n",
    "        \n",
    "        combine_dta = []\n",
    "        combined_logs_num = 0\n",
    "        experiments, combine_experiments = experiments[len(combine_coefs):], experiments[:len(combine_coefs)]\n",
    "        for ((folder, regex), coef) in zip(combine_experiments, combine_coefs):\n",
    "            dta, logs_num = udata.get_log_data_for_experiment(folder, regex, tag, limit_steps)              \n",
    "            \n",
    "            # `coef/np.sum(coefs)` is a weight (coef usually being the number of neurons) for that particular experiment/dataset\n",
    "            dta['Value'] = dta['Value']*coef/np.sum(combine_coefs) \n",
    "            combine_dta.append(dta)\n",
    "            combined_logs_num += logs_num\n",
    "            \n",
    "        # Take first to-be-combined dataframe as basis, accumulate all already weighted others into it\n",
    "        dta = combine_dta[0]       \n",
    "        for df in combine_dta[1:]:\n",
    "            dta['Value'] += df['Value']\n",
    "\n",
    "        line_handle = uasg.analyse_runs(dta, fig=fig, ax=ax, **kwargs)\n",
    "        line_handles.append(line_handle)\n",
    "        if override_legend is None:\n",
    "            legend_names.append(f\"{combine_label} ({combined_logs_num} runs)\")\n",
    "        else:\n",
    "            legend_names.append(override_legend[0])\n",
    "\n",
    "    \n",
    "    # Can't just call uasg.analyse_experiments, with `fig, ax`, would have to pass legend as well... too untidy\n",
    "    for i, (folder, regex) in enumerate(experiments):\n",
    "        dta, logs_num = udata.get_log_data_for_experiment(folder, regex, tag, limit_steps)              \n",
    "        line_handle = uasg.analyse_runs(dta, fig=fig, ax=ax, **kwargs)\n",
    "        \n",
    "        line_handles.append(line_handle)\n",
    "        if override_legend is None:\n",
    "            legend_exp = udata.get_experiment_entries(folder, regex) if experiments_log_in_legend else []\n",
    "            legend_names.append(f\"{regex} ({logs_num} runs) {', '.join(legend_exp)}\")\n",
    "        else:\n",
    "            legend_names.append(f\"{override_legend[i+1]} ({logs_num} runs)\")\n",
    "    \n",
    "    if enable_legend:\n",
    "        ax.legend(line_handles, legend_names)\n",
    "\n",
    "    ax.set_xlabel(\"training epoch\")\n",
    "    ax.set_ylabel(\"mean validation set correlation\")\n",
    "    ax.tick_params(labelleft=True, labelright=True,)\n",
    "    if title: ax.set_title(title)\n",
    "        \n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_analysis(\n",
    "    [ (\"./training_data/logs/experiments_mult1\", f\"bs3_exp91x{i}[^0-9].*test\") for i in range(0, 9, 3)] + \n",
    "    [ (\"./training_data/logs/experiments_mult1\", f\"bs3_exp91x{i}[^0-9].*test\") for i in [25]] + \n",
    "    [ ], \n",
    "    [[103, 55, 102]],\n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"ensamble of individual baseline 3 models (10 runs)\", \"shared model: DoG 25 filters, hidden 20 %, L2 0.1\"],\n",
    "    title=\"Experiment 3.1.1: Combined datasets [1, 2, 3]\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "fig.savefig(figs_folder + \"05_3_1_1_1.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "uasg.summarize_experiments(\n",
    "    [ (\"./training_data/logs/experiments_mult1\", f\"bs3_exp91x{i}[^0-9].*test\") for i in [25]] + \n",
    "    [ ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    title=\"Experiment 3.1.1: Combined datasets [1, 2, 3]\",\n",
    "    figsize=(9.5, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_analysis(\n",
    "    [ (\"./training_data/logs/experiments_mult1\", f\"bs3_exp91x{i}[^0-9].*test\") for i in range(0, 6, 3)] + \n",
    "    [ (\"./training_data/logs/experiments_mult1\", f\"bs3_exp91x{i}[^0-9].*test\") for i in [22]] + \n",
    "    [ ], \n",
    "    [[103, 55]],\n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    override_legend=[\"ensamble of individual baseline 3 models (10 runs)\", \"shared model: DoG 25 filters, hidden 20 %, L2 0.1\"],\n",
    "    title=\"Experiment 3.1.1: Combined datasets [1, 2]\",\n",
    "    figsize=[8, 5]\n",
    ")\n",
    "fig.savefig(figs_folder + \"05_3_1_1_2.pdf\",transparent = True, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "uasg.summarize_experiments(\n",
    "    [ (\"./training_data/logs/experiments_mult1\", f\"bs3_exp91x{i}[^0-9].*test\") for i in [22]] + \n",
    "    [ ], \n",
    "    'loss/correlation/correlation',\n",
    "    (300, 5000),\n",
    "    median_mode=True,\n",
    "    # override_legend=[a for a in range(4)],\n",
    "    title=\"Experiment 3.1.1: Combined datasets [1, 2]\",\n",
    "    figsize=(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}