{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- invastigate models learning \"static model\"\n",
    "- slow ADAM run, does use_gpu work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is in float64 format: 0.0-0.000255\n",
    "def load_data(type='training', region=1):\n",
    "    # `raw_validation_set.npy` is multiple tries non-averaged `validation_set.npy`\n",
    "    return (\n",
    "        (np.load(f'./Data/region{region}/{type}_inputs.npy')*1_000_000).astype(np.uint8),\n",
    "        np.load(f'./Data/region{region}/{type}_set.npy')\n",
    "    )\n",
    "    \n",
    "(input_tr, output_tr) = load_data('training', 1) \n",
    "(val_input, val_output) = load_data('validation', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(input_tr.shape, output_tr.shape)\n",
    "display(val_input.shape, val_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(input_tr.shape)\n",
    "display(input_tr[0])\n",
    "display(input_tr.dtype)\n",
    "display(min(input_tr[0]), max(input_tr[0]), np.mean(input_tr[0]), np.std(input_tr[0]))\n",
    "display(min(input_tr[1]), max(input_tr[1]), np.mean(input_tr[1]), np.std(input_tr[1]))\n",
    "\n",
    "display(output_tr.shape)\n",
    "display(output_tr[0])\n",
    "display(output_tr.dtype)\n",
    "display(min(output_tr[0]), max(output_tr[0]), np.mean(output_tr[0]), np.std(output_tr[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def reshape_single_as_picture(input, size=31):\n",
    "    return np.reshape(input, (size, size))\n",
    "\n",
    "def as_single_picture(input, size=31):\n",
    "    return Image.fromarray(reshape_single_as_picture(input, size), 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(as_single_picture(input_tr[0]))\n",
    "display(as_single_picture(input_tr[2]))\n",
    "display(as_single_picture(input_tr[700]))\n",
    "display(as_single_picture(input_tr[-1]))\n",
    "display(as_single_picture(input_tr[-2]))\n",
    "\n",
    "display(input_tr[0]*1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data trasnform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_input(dta):\n",
    "    def process_single(pic):\n",
    "        resized_pic = as_single_picture(pic).resize(size=(15, 15), resample=Image.BICUBIC)\n",
    "        return np.array(resized_pic).reshape(15*15)\n",
    "    return np.array([process_single(pic) for pic in dta])\n",
    "\n",
    "def normalize_input(dta):\n",
    "    return (dta/np.std(dta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tr_processed = downsample_input(input_tr)\n",
    "display(as_single_picture(input_tr_processed[0], 15))\n",
    "display(as_single_picture(input_tr_processed[2], 15))\n",
    "display(as_single_picture(input_tr_processed[-1], 15))\n",
    "display(as_single_picture(input_tr_processed[-2], 15))\n",
    "\n",
    "display(input_tr_processed[0], min(input_tr_processed[0]), max(input_tr_processed[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, output_shape = output_tr.shape\n",
    "dta_len, input_shape = input_tr_processed.shape\n",
    "display(dta_len, output_shape, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NDN3.NDNutils as NDNutils\n",
    "import NDN3.NDN as NDN\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls = 40\n",
    "d2x = 0.0005\n",
    "l1 = 0.000001\n",
    "\n",
    "hsm_params = NDNutils.ffnetwork_params(\n",
    "    input_dims=[1, input_shape], \n",
    "    layer_sizes=[hls, 2*hls, output_shape],\n",
    "    ei_layers=[0, hls // 2],\n",
    "    normalization=[0], \n",
    "    layer_types=['normal','normal','normal'], \n",
    "    reg_list={\n",
    "        'd2x':[d2x,None,None],\n",
    "        'l1':[l1,None,None],\n",
    "        'max':[None,None,100]})\n",
    "hsm_params['weights_initializers']=['normal','normal','normal']\n",
    "hsm_params['normalize_weights']=[1,0,0]\n",
    "\n",
    "display(hsm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "\n",
    "hsm = NDN.NDN(hsm_params, noise_dist='poisson')\n",
    "hsm.train(\n",
    "    input_data=input_tr_processed, \n",
    "    output_data=output_tr, \n",
    "    train_indxs=np.array(range(dta_len)), \n",
    "    test_indxs=np.array(range(dta_len)), \n",
    "    learning_alg=\"lbfgs\", \n",
    "    opt_params={\n",
    "        'batch_size': 2, 'use_gpu': False, 'epochs_summary': 10, 'epochs_training': 700\n",
    "    }, \n",
    "    output_dir=f\"logs/{time_str}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hsm.generate_prediction(input_tr_processed)\n",
    "display(results[0])\n",
    "display(output_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def get_correlation(a, b):\n",
    "    assert a.shape == b.shape\n",
    "    c = [scipy.stats.pearsonr(a[:,i], b[:,i])[0] for i in range(a.shape[1])]\n",
    "    return np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_correlation(output_tr, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # plotting\n",
    "\n",
    "input_size = [15, 15]\n",
    "nrows, ncols = 3, 4\n",
    "\n",
    "fig, _ = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "fig.set_size_inches(12, 6)\n",
    "for neuron_i in range(nrows * ncols):\n",
    "    plt.subplot(nrows, ncols, neuron_i+1)\n",
    "    w = hsm.networks[0].layers[0].weights[:,neuron_i]\n",
    "    plt.imshow(np.reshape(w, input_size), cmap='Greys', interpolation='none', vmin=-max(abs(w)), vmax=max(abs(w)))\n",
    "plt.show()\n",
    "\n",
    "hsm.networks[0].layers[0].weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_info = hsm.eval_models(input_data=input_tr_processed, output_data=output_tr, data_indxs=np.array(range(dta_len)), nulladjusted=True)\n",
    "eval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.var(results, axis=0))\n",
    "display(np.var(output_tr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "\n",
    "hsm = NDN.NDN(hsm_params, noise_dist='poisson')\n",
    "hsm.train(\n",
    "    input_data=input_tr_processed, \n",
    "    output_data=output_tr, \n",
    "    train_indxs=np.array(range(dta_len)), \n",
    "    test_indxs=np.array(range(dta_len)), \n",
    "    learning_alg=\"adam\", \n",
    "    opt_params={\n",
    "        'batch_size': 2, 'use_gpu': False, 'epochs_summary': 10, 'epochs_training': 700\n",
    "    }, \n",
    "    output_dir=f\"logs/{time_str}\"\n",
    ")\n",
    "eval_info = hsm.eval_models(input_data=input_tr_processed, output_data=output_tr, data_indxs=np.array(range(dta_len)), nulladjusted=True)\n",
    "eval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hsm.generate_prediction(input_tr_processed)\n",
    "display(results[0])\n",
    "display(output_tr[0])\n",
    "display(np.mean(output_tr, axis=0))\n",
    "\n",
    "eval_info = hsm.eval_models(input_data=input_tr_processed, output_data=output_tr, data_indxs=np.array(range(dta_len)), nulladjusted=True)\n",
    "eval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
